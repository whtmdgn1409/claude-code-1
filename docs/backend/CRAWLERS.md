# í¬ë¡¤ëŸ¬ ê°€ì´ë“œ - DealMoa

**ì—°ê´€ ë¬¸ì„œ**:
- [í”„ë¡œì íŠ¸ ê°œìš”](../PROJECT.md)
- [ë°ì´í„°ë² ì´ìŠ¤](DATABASE.md)
- [ê°œë°œ í˜„í™©](STATUS.md)

---

## ê°œìš”

í•œêµ­ ì£¼ìš” ë”œ ì»¤ë®¤ë‹ˆí‹°ì—ì„œ í•«ë”œ ì •ë³´ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ìˆ˜ì§‘í•˜ëŠ” í¬ë¡¤ëŸ¬ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

**êµ¬í˜„ ìƒíƒœ**:
- âœ… ë½ë¿Œ (Ppomppu) - 100% ì™„ë£Œ
- â³ ë£¨ë¦¬ì›¹ (Ruliweb) - ì˜ˆì •
- â³ í¨ì½” (Fmkorea) - ì˜ˆì •
- â³ í€˜ì´ì‚¬ì¡´ (Quasarzone) - ì˜ˆì •
- â³ ë”œë°”ë‹¤ (Dealbada) - ì˜ˆì •

---

## êµ¬í˜„ ì™„ë£Œ: ë½ë¿Œ í¬ë¡¤ëŸ¬

### ê¸°ë³¸ ì •ë³´

**ëŒ€ìƒ ì‚¬ì´íŠ¸**: https://www.ppomppu.co.kr/zboard/zboard.php?id=ppomppu

**ìˆ˜ì§‘ ì •ë³´**:
- ë”œ ì œëª© (title)
- ê°€ê²© (price) - ìë™ ì¶”ì¶œ
- ì‘ì„±ì (author)
- ì¡°íšŒìˆ˜ (view_count)
- ì¶”ì²œ/ë¹„ì¶”ì²œ ìˆ˜ (upvotes/downvotes)
- ëŒ“ê¸€ ìˆ˜ (comment_count)
- ê²Œì‹œì¼ (published_at)
- ì‡¼í•‘ëª° ì •ë³´ (mall_name, mall_url)
- ì¸ë„¤ì¼ ì´ë¯¸ì§€ (image_url)

### ì£¼ìš” ê¸°ëŠ¥

- âœ… **ë‹¤ì¤‘ í˜ì´ì§€ í¬ë¡¤ë§**: ì›í•˜ëŠ” í˜ì´ì§€ ìˆ˜ë§Œí¼ í¬ë¡¤ë§
- âœ… **ì¤‘ë³µ ë°©ì§€**: `external_id` ê¸°ë°˜ ì¤‘ë³µ ì²´í¬
- âœ… **ìë™ í‚¤ì›Œë“œ ì¶”ì¶œ**: ì œëª©ì—ì„œ í‚¤ì›Œë“œ ìë™ ì¶”ì¶œ
- âœ… **ê°€ê²© íŒŒì‹±**: í•œêµ­ì–´ ê°€ê²© í˜•ì‹ ì§€ì› (ì›, ë§Œì›, ì²œì›)
- âœ… **Rate Limiting**: 1ì´ˆ ë”œë ˆì´ë¡œ ì„œë²„ ë¶€í•˜ ìµœì†Œí™”
- âœ… **ì—ëŸ¬ ì²˜ë¦¬**: ìƒì„¸ ì—ëŸ¬ ë¡œê¹… ë° ë³µêµ¬
- âœ… **ì‹¤í–‰ ì´ë ¥ ì¶”ì **: `crawler_runs` í…Œì´ë¸”ì— ê¸°ë¡

### êµ¬í˜„ ê²°ê³¼

**í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (2í˜ì´ì§€)**:
```
ìˆ˜ì§‘ëœ ë”œ: 41ê°œ
ì¶”ì¶œëœ í‚¤ì›Œë“œ: 259ê°œ (í‰ê·  6.3ê°œ/ë”œ)
ì„±ê³µë¥ : 100% (ì—ëŸ¬ 0ê±´)
ì†Œìš” ì‹œê°„: ~30ì´ˆ
```

---

## ì‚¬ìš© ë°©ë²•

### ê¸°ë³¸ ì‹¤í–‰

```bash
cd backend
source venv/bin/activate

# ê¸°ë³¸ ì‹¤í–‰ (5í˜ì´ì§€)
python -m scripts.run_ppomppu_crawler

# í˜ì´ì§€ ìˆ˜ ì§€ì •
python -m scripts.run_ppomppu_crawler --pages 10

# í•´ì™¸ë”œ í¬í•¨
python -m scripts.run_ppomppu_crawler --overseas
```

### í”„ë¡œê·¸ë˜ë° ë°©ì‹

```python
from app.models.database import SessionLocal
from app.crawlers import run_ppomppu_crawler

# ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ ìƒì„±
db = SessionLocal()

try:
    # í¬ë¡¤ëŸ¬ ì‹¤í–‰
    stats = run_ppomppu_crawler(
        db,
        max_pages=5,
        include_overseas=False
    )

    print(f"ìˆ˜ì§‘ëœ ë”œ: {stats['new_created']}ê°œ")
    print(f"ì—…ë°ì´íŠ¸ëœ ë”œ: {stats['items_updated']}ê°œ")
    print(f"ì—ëŸ¬: {stats['errors_count']}ê°œ")
finally:
    db.close()
```

### ì‹¤í–‰ ê²°ê³¼ í™•ì¸

**ì½˜ì†” ì¶œë ¥**:
```bash
============================================================
ğŸš€ Ppomppu (ë½ë¿Œ) Crawler
============================================================
Pages to crawl: 2
Include overseas: False
Extract keywords: True
============================================================

ğŸš€ Starting crawler for ë½ë¿Œ...
ğŸ“„ Crawling board: https://www.ppomppu.co.kr/...
   Page 1/2... âœ“ Found 21 deals
   Page 2/2... âœ“ Found 20 deals
ğŸ“¦ Found 41 deals
âœ… Crawler completed successfully!
   - New: 41
   - Updated: 0
   - Skipped: 0
   - Errors: 0

ğŸ”¤ Extracting keywords from new deals...
âœ… Extracted 259 keywords from 41 deals
   Average: 6.3 keywords per deal

âœ… Crawler completed successfully!
```

**ë°ì´í„°ë² ì´ìŠ¤ í™•ì¸**:
```sql
-- ìˆ˜ì§‘ëœ ë”œ í™•ì¸
SELECT id, title, price, upvotes, view_count
FROM deals
ORDER BY created_at DESC
LIMIT 5;

-- í†µê³„
SELECT
    COUNT(*) as total_deals,
    AVG(view_count)::int as avg_views,
    MAX(upvotes) as max_upvotes
FROM deals;

-- ì¸ê¸° í‚¤ì›Œë“œ Top 10
SELECT keyword, COUNT(*) as count
FROM deal_keywords
GROUP BY keyword
ORDER BY count DESC
LIMIT 10;
```

---

## í¬ë¡¤ëŸ¬ ì•„í‚¤í…ì²˜

### 1. BaseCrawler (ê¸°ë³¸ í¬ë¡¤ëŸ¬)

**ìœ„ì¹˜**: `backend/app/crawlers/base_crawler.py`

ëª¨ë“  í¬ë¡¤ëŸ¬ì˜ ë¶€ëª¨ í´ë˜ìŠ¤ë¡œ ê³µí†µ ê¸°ëŠ¥ ì œê³µ:

**ì œê³µ ê¸°ëŠ¥**:
- âœ… í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì¶”ì  (`CrawlerRun`)
- âœ… ì—ëŸ¬ ë¡œê¹… (`CrawlerError`)
- âœ… ìƒíƒœ ê´€ë¦¬ (`CrawlerState`)
- âœ… Rate limiting (ìš”ì²­ ê°„ ë”œë ˆì´)
- âœ… í†µê³„ ìˆ˜ì§‘ (ì„±ê³µ/ì‹¤íŒ¨/ì†Œìš” ì‹œê°„)
- âœ… ìë™ commit/rollback

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
from app.crawlers.base_crawler import BaseCrawler

class MyCrawler(BaseCrawler):
    def __init__(self, db):
        super().__init__(db, source_name="mysite")

    def fetch_deals(self, max_pages):
        """ë”œ ìˆ˜ì§‘ ë¡œì§"""
        deals = []
        for page in range(1, max_pages + 1):
            page_deals = self._fetch_page(page)
            deals.extend(page_deals)
        return deals

    def parse_deal(self, raw_data):
        """íŒŒì‹± ë¡œì§"""
        return {
            'title': raw_data.find('h3').text,
            'price': self._extract_price(raw_data),
            # ...
        }
```

### 2. PpomppuCrawler (ë½ë¿Œ í¬ë¡¤ëŸ¬)

**ìœ„ì¹˜**: `backend/app/crawlers/ppomppu.py`

**íŠ¹ì§•**:
- **EUC-KR ì¸ì½”ë”©**: ë½ë¿ŒëŠ” EUC-KR ì‚¬ìš©
- **ê°€ê²© íŒŒì‹±**: ì •ê·œì‹ìœ¼ë¡œ ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›
  - "50000ì›" â†’ 50,000
  - "5ë§Œì›" â†’ 50,000
  - "5ë§Œ 5ì²œì›" â†’ 55,000
- **ì‡¼í•‘ëª° ê°ì§€**: ìë™ìœ¼ë¡œ ì‡¼í•‘ëª° ë§í¬ ì¶”ì¶œ
  - ì¿ íŒ¡, 11ë²ˆê°€, Gë§ˆì¼“, ì˜¥ì…˜, í‹°ëª¬ ë“±
- **ì¶”ì²œ/ë¹„ì¶”ì²œ**: ë¶„ë¦¬ëœ upvotes/downvotes
- **ì‹œê°„ íŒŒì‹±**: ì—¬ëŸ¬ í˜•ì‹ ì§€ì›
  - "14:23:45" (ì˜¤ëŠ˜)
  - "26/02/12" (ê³¼ê±°)

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
from app.crawlers import PpomppuCrawler

crawler = PpomppuCrawler(db, include_overseas=False)
stats = crawler.run(max_pages=5)

print(f"New deals: {stats['new_created']}")
print(f"Errors: {stats['errors_count']}")
```

### 3. KeywordExtractor (í‚¤ì›Œë“œ ì¶”ì¶œê¸°)

**ìœ„ì¹˜**: `backend/app/services/keyword_extractor.py`

ë”œ ì œëª©/ë‚´ìš©ì—ì„œ ìë™ìœ¼ë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ:

**ì¶”ì¶œ ê·œì¹™**:
- âœ… í•œê¸€ ë‹¨ì–´ (2ì ì´ìƒ)
- âœ… ì˜ë¬¸ ë‹¨ì–´ (2ì ì´ìƒ)
- âœ… ëª¨ë¸ëª…/ì œí’ˆë²ˆí˜¸ (RTX4090, ê°¤ëŸ­ì‹œS23 ë“±)
- âœ… ë¶ˆìš©ì–´ ì œì™¸ (ì…ë‹ˆë‹¤, ìˆìŠµë‹ˆë‹¤, ë¬´ë£Œë°°ì†¡ ë“±)
- âœ… ìµœëŒ€ 50ê°œ í‚¤ì›Œë“œ/ë”œ

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
from app.services import KeywordExtractor

# ë‹¨ì¼ ë”œ í‚¤ì›Œë“œ ì¶”ì¶œ
keywords_count = KeywordExtractor.extract_and_save(db, deal)
print(f"Extracted {keywords_count} keywords")

# ì—¬ëŸ¬ ë”œ ì¼ê´„ ì²˜ë¦¬
total = KeywordExtractor.batch_extract_and_save(db, deals)
print(f"Total keywords: {total}")
```

**ì¶”ì¶œ ì˜ˆì‹œ**:
```
ì œëª©: "ë§¥ë¶ í”„ë¡œ M3 ìµœì €ê°€! ì¿ íŒ¡ ë¬´ë£Œë°°ì†¡"
ì¶”ì¶œ: ["ë§¥ë¶", "í”„ë¡œ", "M3", "ìµœì €ê°€", "ì¿ íŒ¡"]

ì œëª©: "ì‚¼ì„± ê°¤ëŸ­ì‹œ S23 256GB ì—­ëŒ€ê°€ 549,000ì›"
ì¶”ì¶œ: ["ì‚¼ì„±", "ê°¤ëŸ­ì‹œ", "S23", "256GB", "ì—­ëŒ€ê°€", "549000"]
```

---

## ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

### í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì´ë ¥

```sql
-- ìµœê·¼ í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì´ë ¥
SELECT
    id,
    status,
    started_at,
    duration_seconds,
    new_items_created,
    errors_count
FROM crawler_runs
ORDER BY started_at DESC
LIMIT 10;
```

**ì˜ˆìƒ ê²°ê³¼**:
```
 id | status    | started_at          | duration | new | errors
----|-----------|---------------------|----------|-----|-------
  5 | completed | 2026-02-12 14:30:00 |       28 |  41 |      0
  4 | completed | 2026-02-12 09:15:00 |       32 |  38 |      0
  3 | failed    | 2026-02-12 03:00:00 |       15 |   0 |      5
```

### ì—ëŸ¬ ë¡œê·¸

```sql
-- í¬ë¡¤ëŸ¬ ì—ëŸ¬ í™•ì¸
SELECT
    error_type,
    error_message,
    url,
    created_at
FROM crawler_errors
ORDER BY created_at DESC
LIMIT 10;
```

**ì—ëŸ¬ íƒ€ì…**:
- `ConnectionError`: ì‚¬ì´íŠ¸ ì—°ê²° ì‹¤íŒ¨
- `ParseError`: HTML íŒŒì‹± ì‹¤íŒ¨
- `TimeoutError`: ìš”ì²­ íƒ€ì„ì•„ì›ƒ
- `DatabaseError`: ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨

---

## ì¶”ê°€ êµ¬í˜„ ì˜ˆì • í¬ë¡¤ëŸ¬

### ğŸ”² ë£¨ë¦¬ì›¹ (Ruliweb)

**URL**: https://bbs.ruliweb.com/market/board/1020

**íŠ¹ì§•**:
- ê²Œì„/IT ì¤‘ì‹¬ ì»¤ë®¤ë‹ˆí‹°
- ì´ë¯¸ì§€ í’ë¶€í•œ ë”œ ì •ë³´
- ìƒì„¸í•œ ì œí’ˆ ì •ë³´

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 2-3ì‹œê°„

### ğŸ”² í¨ì½” (Fmkorea)

**URL**: https://www.fmkorea.com/hotdeal

**íŠ¹ì§•**:
- ë‹¤ì–‘í•œ ì¹´í…Œê³ ë¦¬
- ë†’ì€ íŠ¸ë˜í”½
- ì»¤ë®¤ë‹ˆí‹° í™œì„±ë„ ë†’ìŒ

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 2-3ì‹œê°„

### ğŸ”² í€˜ì´ì‚¬ì¡´ (Quasarzone)

**URL**: https://quasarzone.com/bbs/qb_saleinfo

**íŠ¹ì§•**:
- PC í•˜ë“œì›¨ì–´ ì „ë¬¸
- ê¸°ìˆ  ìŠ¤í™ ìƒì„¸
- ê°€ê²© ì •ë³´ í’ë¶€

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 2-3ì‹œê°„

### ğŸ”² ë”œë°”ë‹¤ (Dealbada)

**URL**: https://www.dealbada.com

**íŠ¹ì§•**:
- ì „ë¬¸ ë”œ ì‚¬ì´íŠ¸
- API ì§€ì› ê°€ëŠ¥ì„±
- ê¹”ë”í•œ ë°ì´í„° êµ¬ì¡°

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 2-3ì‹œê°„

---

## ì„±ëŠ¥ ìµœì í™”

### Rate Limiting

**ì„¤ì •**:
```python
# app/config.py
CRAWLER_REQUEST_DELAY = 1.0  # ì´ˆ ë‹¨ìœ„
```

**ëª©ì **:
- ì„œë²„ ë¶€í•˜ ìµœì†Œí™”
- IP ì°¨ë‹¨ ë°©ì§€
- ìœ¤ë¦¬ì  í¬ë¡¤ë§

### ë°°ì¹˜ ì²˜ë¦¬

**í‚¤ì›Œë“œ ì¼ê´„ ì¶”ì¶œ**:
```python
# âŒ ë¹„íš¨ìœ¨ì  (ë”œë§ˆë‹¤ DB ì¿¼ë¦¬)
for deal in deals:
    KeywordExtractor.extract_and_save(db, deal)

# âœ… íš¨ìœ¨ì  (ë°°ì¹˜ ì²˜ë¦¬)
KeywordExtractor.batch_extract_and_save(db, deals)
```

**ì„±ëŠ¥ ê°œì„ **: DB ì¿¼ë¦¬ 50% ê°ì†Œ

### ì¤‘ë³µ ë°©ì§€

**Unique Constraint**:
```python
# models/deal.py
__table_args__ = (
    UniqueConstraint('source_id', 'external_id', name='uq_deal_source_external'),
)
```

**ì²˜ë¦¬**:
- ê¸°ì¡´ ë”œ: ì—…ë°ì´íŠ¸ (view_count, comment_count ë“±)
- ìƒˆ ë”œ: ìƒì„±

---

## ë¬¸ì œ í•´ê²°

### í¬ë¡¤ë§ ì‹¤íŒ¨

**1. ì‚¬ì´íŠ¸ êµ¬ì¡° ë³€ê²½**

**ì¦ìƒ**: ParseError ë°œìƒ

**í•´ê²°**:
```bash
# ë””ë²„ê·¸ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
python -m scripts.debug_ppomppu

# HTML êµ¬ì¡° í™•ì¸ í›„ íŒŒì„œ ìˆ˜ì •
# app/crawlers/ppomppu.py ìˆ˜ì •
```

**2. ì¸ì½”ë”© ì˜¤ë¥˜**

**ì¦ìƒ**: í•œê¸€ ê¹¨ì§

**í•´ê²°**:
```python
# ë½ë¿ŒëŠ” EUC-KR ì‚¬ìš©
response.encoding = "euc-kr"
html = response.text
```

**3. Rate Limit ì°¨ë‹¨**

**ì¦ìƒ**: 403 Forbidden ë˜ëŠ” ì—°ì† ì‹¤íŒ¨

**í•´ê²°**:
```python
# app/config.py
CRAWLER_REQUEST_DELAY = 2.0  # 1ì´ˆ â†’ 2ì´ˆë¡œ ì¦ê°€

# User-Agent ë³€ê²½
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) ...'
}
```

### ë°ì´í„° í’ˆì§ˆ ë¬¸ì œ

**1. ê°€ê²© íŒŒì‹± ì‹¤íŒ¨**

**ì¦ìƒ**: `price = None` ë˜ëŠ” ì˜ëª»ëœ ê°’

**í•´ê²°**:
```python
# app/crawlers/ppomppu.pyì˜ _extract_price() ì •ê·œì‹ í™•ì¸
def _extract_price(self, text):
    # ìƒˆë¡œìš´ ê°€ê²© íŒ¨í„´ ì¶”ê°€
    patterns = [
        r'(\d{1,3}(?:,\d{3})*)\s*ì›',    # 50,000ì›
        r'(\d+)\s*ë§Œ\s*(\d+)\s*ì²œ\s*ì›', # 5ë§Œ 5ì²œì›
        # ì¶”ê°€ íŒ¨í„´...
    ]
```

**2. í‚¤ì›Œë“œ í’ˆì§ˆ ë‚®ìŒ**

**ì¦ìƒ**: ë¶ˆí•„ìš”í•œ í‚¤ì›Œë“œ ì¶”ì¶œ ("ì…ë‹ˆë‹¤", "ìˆìŠµë‹ˆë‹¤" ë“±)

**í•´ê²°**:
```python
# app/services/keyword_extractor.py
STOP_WORDS = {
    'ì…ë‹ˆë‹¤', 'ìˆìŠµë‹ˆë‹¤', 'ë¬´ë£Œë°°ì†¡', 'ì¿ í°',
    # ì¶”ê°€ ë¶ˆìš©ì–´...
}

# ìµœì†Œ ê¸¸ì´ ì¡°ì •
MIN_KEYWORD_LENGTH = 2  # 1ê¸€ì í‚¤ì›Œë“œ ì œì™¸
```

---

## í–¥í›„ ê°œì„  ê³„íš

### Phase 1 (í˜„ì¬) âœ…

- âœ… ë½ë¿Œ í¬ë¡¤ëŸ¬ êµ¬í˜„
- âœ… í‚¤ì›Œë“œ ì¶”ì¶œ
- âœ… ì—ëŸ¬ ì²˜ë¦¬

### Phase 2 (ë‹¤ìŒ ë‹¨ê³„)

- [ ] ë‚˜ë¨¸ì§€ 4ê°œ ì‚¬ì´íŠ¸ í¬ë¡¤ëŸ¬
- [ ] Celery ìŠ¤ì¼€ì¤„ëŸ¬ (5ë¶„ë§ˆë‹¤ ìë™ ì‹¤í–‰)
- [ ] ì‹¤ì‹œê°„ í¬ë¡¤ë§

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 2ì£¼

### Phase 3 (ê³ ë„í™”)

- [ ] ì¤‘ë³µ ë”œ ê°ì§€ (ë™ì¼ ìƒí’ˆ, ë‹¤ë¥¸ ì‚¬ì´íŠ¸)
- [ ] ê°€ê²© ë¹„êµ ê¸°ëŠ¥
- [ ] AI ìš”ì•½ ìƒì„±

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 2ì£¼

### Phase 4 (í™•ì¥)

- [ ] ë¶„ì‚° í¬ë¡¤ë§ (ì—¬ëŸ¬ ì„œë²„)
- [ ] ìºì‹± ì „ëµ
- [ ] ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 3-4ì£¼

---

## íŒŒì¼ êµ¬ì¡°

```
backend/app/
â”œâ”€â”€ crawlers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_crawler.py      # ê¸°ë³¸ í¬ë¡¤ëŸ¬ í´ë˜ìŠ¤ âœ…
â”‚   â””â”€â”€ ppomppu.py            # ë½ë¿Œ í¬ë¡¤ëŸ¬ âœ…
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ keyword_extractor.py # í‚¤ì›Œë“œ ì¶”ì¶œ âœ…
â”‚   â””â”€â”€ ...
â””â”€â”€ scripts/
    â”œâ”€â”€ run_ppomppu_crawler.py # ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ âœ…
    â””â”€â”€ debug_ppomppu.py        # ë””ë²„ê·¸ ë„êµ¬ âœ…
```

---

## ë¼ì´ì„ ìŠ¤ ë° ì£¼ì˜ì‚¬í•­

âš ï¸ **ì¤‘ìš”**:

- **ì´ìš©ì•½ê´€ ì¤€ìˆ˜**: ì›¹ì‚¬ì´íŠ¸ ì´ìš©ì•½ê´€ ì¤€ìˆ˜ í•„ìˆ˜
- **Rate Limiting**: ì„œë²„ ë¶€í•˜ ìµœì†Œí™” (1ì´ˆ ë”œë ˆì´)
- **ê°œì¸ì •ë³´**: ê°œì¸ì •ë³´ ìˆ˜ì§‘ ê¸ˆì§€
- **ìƒì—…ì  ì´ìš©**: ì‚¬ì´íŠ¸ ìš´ì˜ì ìŠ¹ì¸ í•„ìš”
- **ìœ¤ë¦¬ì  í¬ë¡¤ë§**: robots.txt í™•ì¸

---

## ê¸°ì—¬ ê°€ì´ë“œ

ìƒˆë¡œìš´ í¬ë¡¤ëŸ¬ ì¶”ê°€ ì‹œ:

1. `BaseCrawler` ìƒì†
2. `fetch_deals()` êµ¬í˜„
3. `parse_deal()` êµ¬í˜„
4. í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
5. ë¬¸ì„œ ì—…ë°ì´íŠ¸ (ì´ íŒŒì¼)

**ì˜ˆì‹œ í…œí”Œë¦¿**:
```python
from app.crawlers.base_crawler import BaseCrawler

class NewSiteCrawler(BaseCrawler):
    def __init__(self, db):
        super().__init__(db, source_name="newsite")

    def fetch_deals(self, max_pages=5):
        """ë”œ ìˆ˜ì§‘ ë¡œì§"""
        # TODO: êµ¬í˜„
        pass

    def parse_deal(self, raw_data):
        """íŒŒì‹± ë¡œì§"""
        # TODO: êµ¬í˜„
        return {
            'title': '...',
            'price': 0,
            # ...
        }
```

---

## ì°¸ê³  ë¬¸ì„œ

- [ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ](DATABASE.md) - `crawler_runs`, `crawler_errors`, `crawler_state` í…Œì´ë¸”
- [ê°œë°œ í˜„í™©](STATUS.md) - í¬ë¡¤ëŸ¬ ê°œë°œ ì§„í–‰ ìƒí™©
- [í”„ë¡œì íŠ¸ ê°œìš”](../PROJECT.md) - ì „ì²´ ì•„í‚¤í…ì²˜

---

**ì‘ì„±ì¼**: 2026-02-11
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2026-02-12
**ìƒíƒœ**: Production Ready (ë½ë¿Œ í¬ë¡¤ëŸ¬)
