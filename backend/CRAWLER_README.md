# DealMoa í¬ë¡¤ëŸ¬ (Crawler) ë¬¸ì„œ

## ê°œìš”

ë½ë¿Œ(Ppomppu)ë¥¼ ì‹œì‘ìœ¼ë¡œ í•œêµ­ ì£¼ìš” ë”œ ì»¤ë®¤ë‹ˆí‹°ì—ì„œ í•«ë”œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ëŠ” í¬ë¡¤ëŸ¬ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

---

## êµ¬í˜„ëœ í¬ë¡¤ëŸ¬

### âœ… ë½ë¿Œ (Ppomppu) í¬ë¡¤ëŸ¬

**ëŒ€ìƒ ì‚¬ì´íŠ¸**: https://www.ppomppu.co.kr/zboard/zboard.php?id=ppomppu

**ìˆ˜ì§‘ ì •ë³´**:
- ë”œ ì œëª© (title)
- ê°€ê²© (price) - ìë™ ì¶”ì¶œ
- ì‘ì„±ì (author)
- ì¡°íšŒìˆ˜ (view_count)
- ì¶”ì²œìˆ˜ (upvotes/downvotes)
- ëŒ“ê¸€ ìˆ˜ (comment_count)
- ê²Œì‹œì¼ (published_at)
- ì‡¼í•‘ëª° ì •ë³´ (mall_name, mall_url)

**ì£¼ìš” ê¸°ëŠ¥**:
- âœ… ë‹¤ì¤‘ í˜ì´ì§€ í¬ë¡¤ë§
- âœ… ì¤‘ë³µ ë°©ì§€ (external_id ê¸°ë°˜)
- âœ… ìë™ í‚¤ì›Œë“œ ì¶”ì¶œ
- âœ… ê°€ê²© ì •ë³´ íŒŒì‹±
- âœ… Rate limiting (1ì´ˆ ë”œë ˆì´)
- âœ… ì—ëŸ¬ ì²˜ë¦¬ ë° ë¡œê¹…
- âœ… í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì´ë ¥ ì¶”ì 

---

## ì‚¬ìš© ë°©ë²•

### ê¸°ë³¸ ì‹¤í–‰

```bash
cd backend
source venv/bin/activate

# ê¸°ë³¸ ì‹¤í–‰ (5 í˜ì´ì§€)
python -m scripts.run_ppomppu_crawler

# í˜ì´ì§€ ìˆ˜ ì§€ì •
python -m scripts.run_ppomppu_crawler --pages 10

# í•´ì™¸ë”œ í¬í•¨
python -m scripts.run_ppomppu_crawler --overseas
```

### í”„ë¡œê·¸ë˜ë° ë°©ì‹ ì‚¬ìš©

```python
from app.models.database import SessionLocal
from app.crawlers import run_ppomppu_crawler

# ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ ìƒì„±
db = SessionLocal()

try:
    # í¬ë¡¤ëŸ¬ ì‹¤í–‰
    stats = run_ppomppu_crawler(
        db,
        max_pages=5,
        include_overseas=False
    )

    print(f"ìˆ˜ì§‘ëœ ë”œ: {stats['new_created']}ê°œ")
finally:
    db.close()
```

---

## í¬ë¡¤ëŸ¬ ì•„í‚¤í…ì²˜

### 1. BaseCrawler (ê¸°ë³¸ í¬ë¡¤ëŸ¬ í´ë˜ìŠ¤)

ëª¨ë“  í¬ë¡¤ëŸ¬ì˜ ë¶€ëª¨ í´ë˜ìŠ¤ë¡œ ê³µí†µ ê¸°ëŠ¥ ì œê³µ:

```python
from app.crawlers.base_crawler import BaseCrawler

class MyCrawler(BaseCrawler):
    def __init__(self, db):
        super().__init__(db, source_name="mysite")

    def fetch_deals(self, max_pages):
        # ë”œ ìˆ˜ì§‘ ë¡œì§
        pass

    def parse_deal(self, raw_data):
        # íŒŒì‹± ë¡œì§
        pass
```

**ì œê³µ ê¸°ëŠ¥**:
- âœ… í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì¶”ì  (CrawlerRun)
- âœ… ì—ëŸ¬ ë¡œê¹… (CrawlerError)
- âœ… ìƒíƒœ ê´€ë¦¬ (CrawlerState)
- âœ… Rate limiting
- âœ… í†µê³„ ìˆ˜ì§‘
- âœ… ìë™ commit/rollback

### 2. PpomppuCrawler (ë½ë¿Œ í¬ë¡¤ëŸ¬)

```python
from app.crawlers import PpomppuCrawler

crawler = PpomppuCrawler(db, include_overseas=False)
stats = crawler.run(max_pages=5)
```

**íŠ¹ì§•**:
- EUC-KR ì¸ì½”ë”© ì²˜ë¦¬
- í•œêµ­ì–´ ê°€ê²© íŒŒì‹± (ì›, ë§Œì›, ì²œì›)
- ì‡¼í•‘ëª° ìë™ ê°ì§€ (ì¿ íŒ¡, 11ë²ˆê°€, Gë§ˆì¼“ ë“±)
- ì¶”ì²œìˆ˜/ë¹„ì¶”ì²œìˆ˜ ë¶„ë¦¬
- ì‹œê°„ í˜•ì‹ íŒŒì‹± (HH:MM:SS, YY/MM/DD)

### 3. KeywordExtractor (í‚¤ì›Œë“œ ì¶”ì¶œê¸°)

ë”œ ì œëª©/ë‚´ìš©ì—ì„œ ìë™ìœ¼ë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ:

```python
from app.services import KeywordExtractor

# ë‹¨ì¼ ë”œ í‚¤ì›Œë“œ ì¶”ì¶œ
keywords_count = KeywordExtractor.extract_and_save(db, deal)

# ì—¬ëŸ¬ ë”œ ì¼ê´„ ì²˜ë¦¬
total = KeywordExtractor.batch_extract_and_save(db, deals)
```

**ì¶”ì¶œ ê·œì¹™**:
- í•œê¸€ ë‹¨ì–´ (2ì ì´ìƒ)
- ì˜ë¬¸ ë‹¨ì–´ (2ì ì´ìƒ)
- ëª¨ë¸ëª…/ì œí’ˆë²ˆí˜¸ (RTX4090, ê°¤ëŸ­ì‹œS23 ë“±)
- ë¶ˆìš©ì–´ ì œì™¸ (ì…ë‹ˆë‹¤, ìˆìŠµë‹ˆë‹¤ ë“±)
- ìµœëŒ€ 50ê°œ í‚¤ì›Œë“œ/ë”œ

---

## í¬ë¡¤ëŸ¬ ì‹¤í–‰ ê²°ê³¼

### ì„±ê³µì ì¸ ì‹¤í–‰ ì˜ˆì‹œ

```bash
============================================================
ğŸš€ Ppomppu (ë½ë¿Œ) Crawler
============================================================
Pages to crawl: 2
Include overseas: False
Extract keywords: True
============================================================

ğŸš€ Starting crawler for ë½ë¿Œ...
ğŸ“„ Crawling board: https://www.ppomppu.co.kr/zboard/zboard.php?id=ppomppu
   Page 1/2... âœ“ Found 21 deals
   Page 2/2... âœ“ Found 20 deals
ğŸ“¦ Found 41 deals
âœ… Crawler completed successfully!
   - New: 41
   - Updated: 0
   - Skipped: 0
   - Errors: 0

============================================================
ğŸ“Š Crawling Results
============================================================
Total found: 41
New deals: 41
Updated deals: 0
Skipped: 0
Errors: 0
============================================================

ğŸ”¤ Extracting keywords from new deals...
âœ… Extracted 259 keywords from 41 deals
   Average: 6.3 keywords per deal

âœ… Crawler completed successfully!
```

### ë°ì´í„°ë² ì´ìŠ¤ í™•ì¸

```sql
-- ìˆ˜ì§‘ëœ ë”œ í™•ì¸
SELECT id, title, price, upvotes, view_count
FROM deals
ORDER BY created_at DESC
LIMIT 5;

-- í†µê³„
SELECT
    COUNT(*) as total_deals,
    AVG(view_count)::int as avg_views,
    MAX(upvotes) as max_upvotes
FROM deals;

-- ì¸ê¸° í‚¤ì›Œë“œ
SELECT keyword, COUNT(*) as count
FROM deal_keywords
GROUP BY keyword
ORDER BY count DESC
LIMIT 10;
```

**ì‹¤ì œ ê²°ê³¼**:
```
ì´ ë”œ: 41ê°œ
í‰ê·  ì¡°íšŒìˆ˜: 2,641
ìµœëŒ€ ì¶”ì²œìˆ˜: 10
ì¸ê¸° í‚¤ì›Œë“œ: ë¬´ë£Œ(26), ë¬´ë°°(10), ë„¤ì´ë²„(10), 11ë²ˆê°€(7), ì§€ë§ˆì¼“(5)
```

---

## ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

### í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì´ë ¥

```sql
-- ìµœê·¼ í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì´ë ¥
SELECT
    id,
    status,
    started_at,
    duration_seconds,
    new_items_created,
    errors_count
FROM crawler_runs
ORDER BY started_at DESC
LIMIT 10;
```

### ì—ëŸ¬ ë¡œê·¸

```sql
-- í¬ë¡¤ëŸ¬ ì—ëŸ¬ í™•ì¸
SELECT
    error_type,
    error_message,
    url,
    created_at
FROM crawler_errors
ORDER BY created_at DESC
LIMIT 10;
```

---

## ì¶”ê°€ êµ¬í˜„ ì˜ˆì • í¬ë¡¤ëŸ¬

### ğŸ”² ë£¨ë¦¬ì›¹ (Ruliweb)
- URL: https://bbs.ruliweb.com/market/board/1020
- íŠ¹ì§•: ê²Œì„/IT ì¤‘ì‹¬ ë”œ

### ğŸ”² í¨ì½” (Fmkorea)
- URL: https://www.fmkorea.com/hotdeal
- íŠ¹ì§•: ë‹¤ì–‘í•œ ì¹´í…Œê³ ë¦¬

### ğŸ”² í€˜ì´ì‚¬ì¡´ (Quasarzone)
- URL: https://quasarzone.com/bbs/qb_saleinfo
- íŠ¹ì§•: PC í•˜ë“œì›¨ì–´ ì¤‘ì‹¬

### ğŸ”² ë”œë°”ë‹¤ (Dealbada)
- URL: https://www.dealbada.com
- íŠ¹ì§•: ì „ë¬¸ ë”œ ì‚¬ì´íŠ¸

---

## ì„±ëŠ¥ ìµœì í™”

### Rate Limiting
```python
# app/config.py
CRAWLER_REQUEST_DELAY = 1.0  # ì´ˆ ë‹¨ìœ„
```

### ë°°ì¹˜ ì²˜ë¦¬
```python
# í‚¤ì›Œë“œ ì¼ê´„ ì¶”ì¶œ (DB ì¿¼ë¦¬ ìµœì†Œí™”)
KeywordExtractor.batch_extract_and_save(db, deals)
```

### ì¤‘ë³µ ë°©ì§€
- `source_id + external_id` unique constraint
- ê¸°ì¡´ ë”œì€ ì—…ë°ì´íŠ¸ë§Œ ìˆ˜í–‰

---

## ë¬¸ì œ í•´ê²°

### í¬ë¡¤ë§ì´ ì‹¤íŒ¨í•˜ëŠ” ê²½ìš°

1. **ì‚¬ì´íŠ¸ êµ¬ì¡° ë³€ê²½**
   - `scripts/debug_ppomppu.py` ì‹¤í–‰
   - HTML êµ¬ì¡° í™•ì¸ í›„ íŒŒì„œ ìˆ˜ì •

2. **ì¸ì½”ë”© ì˜¤ë¥˜**
   ```python
   response.encoding = "euc-kr"  # ë½ë¿ŒëŠ” EUC-KR
   ```

3. **Rate Limit ì°¨ë‹¨**
   - `CRAWLER_REQUEST_DELAY` ì¦ê°€
   - User-Agent ë³€ê²½

### ë°ì´í„° í’ˆì§ˆ ë¬¸ì œ

1. **ê°€ê²© íŒŒì‹± ì‹¤íŒ¨**
   - `_extract_price()` ë©”ì„œë“œ ì •ê·œì‹ í™•ì¸
   - ìƒˆë¡œìš´ ê°€ê²© íŒ¨í„´ ì¶”ê°€

2. **í‚¤ì›Œë“œ í’ˆì§ˆ ë‚®ìŒ**
   - `STOP_WORDS` ë¶ˆìš©ì–´ ì¶”ê°€
   - `MIN_KEYWORD_LENGTH` ì¡°ì •

---

## í–¥í›„ ê°œì„  ê³„íš

### Phase 1 (í˜„ì¬)
- âœ… ë½ë¿Œ í¬ë¡¤ëŸ¬ êµ¬í˜„
- âœ… í‚¤ì›Œë“œ ì¶”ì¶œ
- âœ… ì—ëŸ¬ ì²˜ë¦¬

### Phase 2
- [ ] ë‚˜ë¨¸ì§€ 4ê°œ ì‚¬ì´íŠ¸ í¬ë¡¤ëŸ¬
- [ ] ìŠ¤ì¼€ì¤„ëŸ¬ (Celery)
- [ ] ì‹¤ì‹œê°„ í¬ë¡¤ë§ (5ë¶„ ê°„ê²©)

### Phase 3
- [ ] ì¤‘ë³µ ë”œ ê°ì§€ (ë™ì¼ ìƒí’ˆ ë‹¤ë¥¸ ì‚¬ì´íŠ¸)
- [ ] ê°€ê²© ë¹„êµ ê¸°ëŠ¥
- [ ] AI ìš”ì•½ ìƒì„±

### Phase 4
- [ ] ë¶„ì‚° í¬ë¡¤ë§ (ì—¬ëŸ¬ ì„œë²„)
- [ ] ìºì‹± ì „ëµ
- [ ] ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ

---

## ë¼ì´ì„ ìŠ¤ ë° ì£¼ì˜ì‚¬í•­

âš ï¸ **ì¤‘ìš”**:
- ì›¹ì‚¬ì´íŠ¸ ì´ìš©ì•½ê´€ ì¤€ìˆ˜ í•„ìˆ˜
- Rate limitingì„ í†µí•œ ì„œë²„ ë¶€í•˜ ìµœì†Œí™”
- ê°œì¸ì •ë³´ ìˆ˜ì§‘ ê¸ˆì§€
- ìƒì—…ì  ì´ìš© ì‹œ ì‚¬ì´íŠ¸ ìš´ì˜ì ìŠ¹ì¸ í•„ìš”

---

## ê¸°ì—¬

ìƒˆë¡œìš´ í¬ë¡¤ëŸ¬ ì¶”ê°€ ì‹œ:
1. `BaseCrawler` ìƒì†
2. `fetch_deals()` êµ¬í˜„
3. `parse_deal()` êµ¬í˜„
4. í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
5. ë¬¸ì„œ ì—…ë°ì´íŠ¸

---

**ì‘ì„±ì¼**: 2026-02-11
**ë²„ì „**: 1.0.0
**ìƒíƒœ**: Production Ready (ë½ë¿Œ í¬ë¡¤ëŸ¬)
